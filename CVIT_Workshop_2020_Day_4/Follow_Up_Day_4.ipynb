{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Follow Up Day 4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG3rKnYUpqiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall opencv-python -y\n",
        "# downgrade OpenCV a bit since some none-free features are not avilable\n",
        "!pip install opencv-contrib-python==3.4.2.17 --force-reinstall"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQyMSA5cptfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import basic functions\n",
        "import numpy as np \n",
        "import cv2\n",
        "import glob\n",
        "import os \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ6clASdp2H2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmhoehWgp4je",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls 'drive/My Drive/CVIT Day 4/Feature Matching/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TUItKxup71G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image1=cv2.imread('drive/My Drive/CVIT Day 4/Feature Matching/box.png',cv2.IMREAD_GRAYSCALE)\n",
        "image2=cv2.imread('drive/My Drive/CVIT Day 4/Feature Matching/box_in_scene.png',cv2.IMREAD_GRAYSCALE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrCKsbGc0qko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initiate ORB detector\n",
        "orb = cv2.ORB_create()\n",
        "# find the keypoints and descriptors with ORB\n",
        "kp1, des1 = orb.detectAndCompute(image1,None)\n",
        "kp2, des2 = orb.detectAndCompute(image2,None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4X1CT5bp-YZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initiate Sift detector\n",
        "sift =cv2.xfeatures2d.SIFT_create()\n",
        "kp1, des1 = sift.detectAndCompute(image1,None)\n",
        "kp2, des2 = sift.detectAndCompute(image2,None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCp3e1y9qCCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(cv2.drawKeypoints(image1,kp1,None,color=(0,255,0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQVHz11vyLtN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display the keypoints and features detected on both images\n",
        "fig, (ax1,ax2) = plt.subplots(nrows=1, ncols=2, figsize=(20,8), constrained_layout=False)\n",
        "ax1.imshow(cv2.drawKeypoints(image1,kp1,None,color=(0,255,0)))\n",
        "ax1.set_xlabel(\"(a)\", fontsize=14)\n",
        "ax2.imshow(cv2.drawKeypoints(image2,kp2,None,color=(0,255,0)))\n",
        "ax2.set_xlabel(\"(b)\", fontsize=14)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj1B31y9yPbv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "match = cv2.BFMatcher()\n",
        "matches = match.knnMatch(des1,des2,k=2)\n",
        "\n",
        "good = []\n",
        "for m,n in matches:\n",
        "    if m.distance < 0.7*n.distance:\n",
        "        good.append(m)\n",
        "\n",
        "draw_params = dict(matchColor=(0,255,0),\n",
        "                       singlePointColor=None,\n",
        "                       flags=2)\n",
        "\n",
        "img3 = cv2.drawMatches(image1,kp1,image2,kp2,good,None,**draw_params)\n",
        "plt.imshow(img3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZEL6g1lyL-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2u6vxgpL2Rbm",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I09V-Ia92RnB",
        "colab_type": "text"
      },
      "source": [
        "## Panorama"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUfxaapW2WVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image1=cv2.imread('drive/My Drive/CVIT Day 4/Panorama/Eg1/img2_2.png')\n",
        "image2=cv2.imread('drive/My Drive/CVIT Day 4/Panorama/Eg1/img2_1.png')\n",
        "\n",
        "image1_gray=cv2.cvtColor(image1,cv2.COLOR_BGR2GRAY)\n",
        "image2_gray=cv2.cvtColor(image2,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "image1=cv2.cvtColor(image1,cv2.COLOR_BGR2RGB)\n",
        "image2=cv2.cvtColor(image2,cv2.COLOR_BGR2RGB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYpR1TUG2Ylm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# find the keypoints and descriptors with ORB\n",
        "kp1, des1 = orb.detectAndCompute(image1_gray,None)\n",
        "kp2, des2 = orb.detectAndCompute(image2_gray,None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9iHDOAO2bzT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initiate Sift detector\n",
        "sift =cv2.xfeatures2d.SIFT_create()\n",
        "kp1, des1 = sift.detectAndCompute(image1_gray,None)\n",
        "kp2, des2 = sift.detectAndCompute(image2_gray,None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofPVYKcx2f3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display the keypoints and features detected on both images\n",
        "fig, (ax1,ax2) = plt.subplots(nrows=1, ncols=2, figsize=(20,8), constrained_layout=False)\n",
        "ax1.imshow(cv2.drawKeypoints(image1_gray,kp1,None,color=(0,255,0)))\n",
        "ax1.set_xlabel(\"(a)\", fontsize=14)\n",
        "ax2.imshow(cv2.drawKeypoints(image2_gray,kp2,None,color=(0,255,0)))\n",
        "ax2.set_xlabel(\"(b)\", fontsize=14)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiaGzgpK2lkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "match = cv2.BFMatcher()\n",
        "matches = match.knnMatch(des1,des2,k=2)\n",
        "\n",
        "good = []\n",
        "for m,n in matches:\n",
        "    if m.distance < 0.03*n.distance:\n",
        "        good.append(m)\n",
        "\n",
        "draw_params = dict(matchColor=(0,255,0),\n",
        "                       singlePointColor=None,\n",
        "                       flags=2)\n",
        "\n",
        "img3 = cv2.drawMatches(image1_gray,kp1,image2_gray,kp2,good,None,**draw_params)\n",
        "plt.imshow(img3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALvKmm_i21YB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MIN_MATCH_COUNT = 10\n",
        "if len(good) > MIN_MATCH_COUNT:\n",
        "    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
        "    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
        "\n",
        "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
        "\n",
        "    h,w = image2_gray.shape\n",
        "    pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
        "    dst = cv2.perspectiveTransform(pts, M)\n",
        "    #img2 = cv2.polylines(image2,[np.int32(dst)],True,255,3, cv2.LINE_AA)\n",
        "\n",
        "    #plt.imshow(img2)\n",
        "else:\n",
        "    print(\"Not enought matches are found - %d/%d\", (len(good)/MIN_MATCH_COUNT))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odZVIrDg3fGU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dst = cv2.warpPerspective(image1,M,(image2.shape[1] + image1.shape[1], image2.shape[0]))\n",
        "dst[0:image2.shape[0],0:image2.shape[1]] = image2\n",
        "plt.imshow(dst)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gNTcFlt4Srn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trim(frame):\n",
        "    #crop top\n",
        "    if not np.sum(frame[0]):\n",
        "        return trim(frame[1:])\n",
        "    #crop bottom\n",
        "    if not np.sum(frame[-1]):\n",
        "        return trim(frame[:-2])\n",
        "    #crop left\n",
        "    if not np.sum(frame[:,0]):\n",
        "        return trim(frame[:,1:])\n",
        "    #crop right\n",
        "    if not np.sum(frame[:,-1]):\n",
        "        return trim(frame[:,:-2])\n",
        "    return frame\n",
        "\n",
        "plt.imshow(trim(dst))\n",
        "#cv2.imsave(\"original_image_stitched_crop.jpg\", trim(dst))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5GtFR7o9jcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ksbmbapm9je_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSG-ubQc9pKl",
        "colab_type": "text"
      },
      "source": [
        "## Panorama as a function for dealing with multiple images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd6jKAnC9jiq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trim(frame):\n",
        "          #crop top\n",
        "          if not np.sum(frame[0]):\n",
        "              return trim(frame[1:])\n",
        "          #crop bottom\n",
        "          if not np.sum(frame[-1]):\n",
        "              return trim(frame[:-2])\n",
        "          #crop left\n",
        "          if not np.sum(frame[:,0]):\n",
        "              return trim(frame[:,1:])\n",
        "          #crop right\n",
        "          if not np.sum(frame[:,-1]):\n",
        "              return trim(frame[:,:-2])\n",
        "          return frame\n",
        "\n",
        "def panorama(path_right,path_left):\n",
        "\n",
        "      image1=cv2.imread(path_right)\n",
        "      image2=cv2.imread(path_left)\n",
        "\n",
        "      image1_gray=cv2.cvtColor(image1,cv2.COLOR_BGR2GRAY)\n",
        "      image2_gray=cv2.cvtColor(image2,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "      image1=cv2.cvtColor(image1,cv2.COLOR_BGR2RGB)\n",
        "      image2=cv2.cvtColor(image2,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "      # Initiate Sift detector\n",
        "      sift =cv2.xfeatures2d.SIFT_create()\n",
        "      kp1, des1 = sift.detectAndCompute(image1_gray,None)\n",
        "      kp2, des2 = sift.detectAndCompute(image2_gray,None)\n",
        "\n",
        "      # display the keypoints and features detected on both images\n",
        "      #fig, (ax1,ax2) = plt.subplots(nrows=1, ncols=2, figsize=(20,8), constrained_layout=False)\n",
        "      #ax1.imshow(cv2.drawKeypoints(image1_gray,kp1,None,color=(0,255,0)))\n",
        "      #ax1.set_xlabel(\"(a)\", fontsize=14)\n",
        "      #ax2.imshow(cv2.drawKeypoints(image2_gray,kp2,None,color=(0,255,0)))\n",
        "      #ax2.set_xlabel(\"(b)\", fontsize=14)\n",
        "\n",
        "      match = cv2.BFMatcher()\n",
        "      matches = match.knnMatch(des1,des2,k=2)\n",
        "\n",
        "      good = []\n",
        "      for m,n in matches:\n",
        "          if m.distance < 0.03*n.distance:\n",
        "              good.append(m)\n",
        "\n",
        "      draw_params = dict(matchColor=(0,255,0),\n",
        "                            singlePointColor=None,\n",
        "                            flags=2)\n",
        "\n",
        "      img3 = cv2.drawMatches(image1_gray,kp1,image2_gray,kp2,good,None,**draw_params)\n",
        "      #plt.imshow(img3)\n",
        "\n",
        "      MIN_MATCH_COUNT = 10\n",
        "      if len(good) > MIN_MATCH_COUNT:\n",
        "          src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
        "          dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
        "\n",
        "          M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
        "\n",
        "          h,w = image2_gray.shape\n",
        "          pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
        "          dst = cv2.perspectiveTransform(pts, M)\n",
        "          #img2 = cv2.polylines(image2,[np.int32(dst)],True,255,3, cv2.LINE_AA)\n",
        "\n",
        "          #plt.imshow(img2)\n",
        "      else:\n",
        "          print(\"Not enought matches are found - %d/%d\", (len(good)/MIN_MATCH_COUNT))\n",
        "\n",
        "      dst = cv2.warpPerspective(image1,M,(image2.shape[1] + image1.shape[1], image2.shape[0]+ image1.shape[0]))\n",
        "      dst[0:image2.shape[0],0:image2.shape[1]] = image2\n",
        "      #plt.imshow(dst)\n",
        "\n",
        "      \n",
        "      #plt.imshow(trim(dst))\n",
        "      #cv2.imsave(\"original_image_stitched_crop.jpg\", trim(dst))\n",
        "      return(trim(dst))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iasmpgVM9r1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root='drive/My Drive/CVIT Day 4/Panorama/Eg2/'\n",
        "images=os.listdir(root)\n",
        "save_path='drive/My Drive/CVIT Day 4/Panorama/Outputs/Eg2/'\n",
        "for i in range (len(images)-1):\n",
        "  path_right=root+images[i+1] \n",
        "  if i==0:\n",
        "    path_left=root+images[i]\n",
        "  else:\n",
        "    path_left=save_image\n",
        "  img_new=panorama(path_right,path_left)\n",
        "  save_image=save_path+images[i+1][:-4]+\"output.png\"\n",
        "  cv2.imwrite(save_image, cv2.cvtColor(img_new, cv2.COLOR_RGB2BGR)) "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}